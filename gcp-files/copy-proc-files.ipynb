{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a39958e-f351-40ea-ba71-707381af9a28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Move processed GCS glider imagery files\n",
    "\n",
    "The code for processiong shadowgraph images (Cutter's code, adapted from Ohman et al methods, in us-amlr/amlr-shadowgraph) wrote out processed images into a single directory. The purpose of this notebook is to copy these files to their own folders, to be imported into VIAME-Web-AMLR.\n",
    "\n",
    "Image types: \n",
    "- -ffPCG.png images: Flatfielded images, with Pixel Gamma Correction\n",
    "- -imgff.png images: Flatfielded images\n",
    "- .jpgorig-regions.jpg: Original jpg images, with red region bounding boxes pasted onto them\n",
    "\n",
    "Note that both versions of flatfielded images have had other processing steps applied, such as masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50b154a-8477-4e63-b4c6-f50ffb1852a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from filemgmt.utils import replace_path, create_pre\n",
    "from filemgmt.gcs import list_blobs_with_prefix, copy_blob_client\n",
    "\n",
    "# from google.cloud import storage\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1074a-5c1b-4c19-bfea-70f8cf125a4a",
   "metadata": {},
   "source": [
    "## Set variable names\n",
    "User tasks: update variable names as necessary in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e94e0d-61c0-4773-ab41-e47a5b67b994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_source_name      = \"amlr-imagery-proc-dev\"\n",
    "bucket_destination_name = \"amlr-gliders-imagery-proc-dev\"\n",
    "\n",
    "glider_deployment = \"ringo-20240312\"\n",
    "# glider_deployment = \"amlr07-20221204\"\n",
    "pre_source, pre_destination = create_pre(glider_deployment)\n",
    "\n",
    "file_prefix_base = f\"{pre_source}/{glider_deployment}/shadowgraph/images\"\n",
    "\n",
    "# file_substr    = \"-ffPCG\"\n",
    "# file_substr    = \"-imgff\"\n",
    "file_substr    = \"jpgorig-regions\"\n",
    "\n",
    "# NOTE: if changing the directory prefix, you may have to update number of leading 0s in dir_paste\n",
    "dir_range = range(0, 1) \n",
    "def dir_paste(y):\n",
    "    return f\"Dir0{y:02}\"\n",
    "\n",
    "# Printing for sanity checks\n",
    "print(f\"base: {file_prefix_base}\")\n",
    "print(f\"substring: {file_substr}\")\n",
    "print(f\"Directories: {dir_range}\")\n",
    "print(f\"Example directory: {dir_paste(dir_range[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4c97e2-9f03-4b01-aa65-09bd1ee2902a",
   "metadata": {},
   "source": [
    "## Copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc88a22-47f1-45ad-a341-207d7fa7d1af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numcores = mp.cpu_count()\n",
    "print(f\"Running with {numcores} cores\")\n",
    "\n",
    "# storage_client = storage.Client(project = \"ggn-nmfs-usamlr-dev-7b99\")\n",
    "# source_bucket = storage_client.bucket(bucket_source_name)\n",
    "# destination_bucket = storage_client.bucket(bucket_destination_name)\n",
    "\n",
    "print(f\"\\nStart time of all: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "for z in dir_range:    \n",
    "    file_prefix = f\"{file_prefix_base}/{dir_paste(z)}\"\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(file_prefix)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    file_list_orig = list_blobs_with_prefix(\n",
    "        bucket_source_name, file_prefix, file_substr=file_substr)   \n",
    "    \n",
    "    file_list_destination = [replace_path(i, file_substr, pre_source, pre_destination) for i in file_list_orig]\n",
    "        \n",
    "    print(f\"copying {len(file_list_orig)} files with '{file_substr}' \" +\n",
    "        f\"with the prefix '{bucket_source_name}/{file_prefix}'\")\n",
    "    print(f\"destination list length: {len(file_list_destination)}\")\n",
    "        \n",
    "    # In parallel\n",
    "    with mp.Pool(numcores) as pool:\n",
    "        out_list = pool.starmap(\n",
    "            copy_blob_client, \n",
    "            zip(repeat(bucket_source_name), file_list_orig, \n",
    "                repeat(bucket_destination_name), file_list_destination)\n",
    "        )\n",
    "        \n",
    "    # # Not in parallel\n",
    "    # for (i, j) in zip(file_list_orig, file_list_destination):\n",
    "    #     if destination_bucket.blob(j).exists():\n",
    "    #         continue\n",
    "    #         # print(f\"skipping {destination_bucket.blob(j).name}\")\n",
    "    #     else:\n",
    "    #         copy_blob(source_bucket, i, destination_bucket, j)\n",
    "            \n",
    "    print(f\"Time is {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Full z runtime: {(time.time()-start_time)/60} minutes\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-muggle-gcp-files-muggle-gcp-files",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "muggle-gcp-files (Local)",
   "language": "python",
   "name": "conda-env-muggle-gcp-files-muggle-gcp-files"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
