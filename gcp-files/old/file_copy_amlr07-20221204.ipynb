{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db53c055-66e2-46d3-9a53-1cd50436a1f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Move amlr07-20221204 GCS files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32cd3a-2703-4d59-8679-86699d37f08e",
   "metadata": {},
   "source": [
    "The code for processiong amlr07-20221204 shadowgraph images (Cutter's code, adapted from Ohman et al methods) wrote out processed images into a single directory. The purpose of this notebook is to copy these files to their own folders, to be imported into VIAME-Web-AMLR.\n",
    "\n",
    "Image types: \n",
    "- -ffPCG.png images: Flatfielded images, with Pixel Gamma Correction\n",
    "- -imgff.png images: Flatfielded images\n",
    "- .jpgorig-regions.jpg: Original jpg images, with red region bounding boxes pasted onto them\n",
    "\n",
    "Note that both versions of flatfielded images have had other processing steps applied, such as masking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c8ac6f-8fb3-4920-aa81-e126829f7422",
   "metadata": {},
   "source": [
    "Import modules, inlcuding 'sourcing' py file with functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d86634-a714-493d-ae8c-b66e0c1725b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from itertools import repeat\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "%run -m file_move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef086f24-9dff-4393-b65c-e091f798a3d0",
   "metadata": {},
   "source": [
    "## Variables and Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83365d3-2538-44fb-aa35-decfc1a2c920",
   "metadata": {},
   "source": [
    "Set variable names, and generate list of files to rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3174b6b9-b336-4d38-86f2-97f407b538e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project = \"ggn-nmfs-usamlr-dev-7b99\")\n",
    "source_bucket_name    = \"amlr-imagery-proc-dev\"\n",
    "destination_bucket_name = \"amlr-gliders-imagery-proc-dev\"\n",
    "\n",
    "source_bucket = storage_client.bucket(source_bucket_name)\n",
    "destination_bucket = storage_client.bucket(destination_bucket_name)\n",
    "\n",
    "# file_substr    = \"-ffPCG\"\n",
    "# file_substr    = \"-imgff\"\n",
    "file_substr    = \"jpgorig-regions\"\n",
    "\n",
    "numcores = mp.cpu_count()\n",
    "print(f\"Running with {numcores} cores\")\n",
    "\n",
    "print(f\"\\nStart time of all: {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "# for z in range(0, 32):    \n",
    "for z in range(0, 32):    \n",
    "    file_prefix = f\"gliders/2022/amlr07-20221204/shadowgraph/images/Dir0{z:02}\"\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(file_prefix)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    file_list_orig = list_blobs_with_prefix(\n",
    "        source_bucket_name, file_prefix, file_substr=file_substr)   \n",
    "    \n",
    "    file_list_destination = []\n",
    "    for i in file_list_orig:\n",
    "        i_orig = i\n",
    "        i = i.replace(\"gliders/2022\", \"FREEBYRD/2023\")\n",
    "        i = i.replace(\"/shadowgraph/images\", f\"/images{file_substr}\")\n",
    "        i = i.replace(\"/output\", \"\")\n",
    "        file_list_destination.append(i)\n",
    "        \n",
    "    print(f\"copying {len(file_list_orig)} files with {file_substr} \" +\n",
    "        f\"with the prefix {source_bucket_name}/{file_prefix}\")\n",
    "    print(f\"destination list list length: {len(file_list_destination)}\")\n",
    "        \n",
    "    with mp.Pool(numcores) as pool:\n",
    "        out_list = pool.starmap(\n",
    "            copy_blob_client, \n",
    "            zip(repeat(source_bucket_name), file_list_orig, \n",
    "                repeat(destination_bucket_name), file_list_destination)\n",
    "        )\n",
    "        \n",
    "    # for (i, j) in zip(file_list_orig, file_list_destination):\n",
    "    #     if destination_bucket.blob(j).exists():\n",
    "    #         continue\n",
    "    #         # print(f\"skipping {destination_bucket.blob(j).name}\")\n",
    "    #     else:\n",
    "    #         copy_blob(source_bucket, i, destination_bucket, j)\n",
    "            \n",
    "    print(f\"Time is {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Full z runtime: {(time.time()-start_time)/60} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
