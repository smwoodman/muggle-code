{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da42a4f5-57b0-4a2e-b182-0c5a0fb19883",
   "metadata": {},
   "source": [
    "# Rsync GCS glider regions files\n",
    "\n",
    "The code for processiong shadowgraph images (Cutter's code, adapted from Ohman et al methods, in us-amlr/amlr-shadowgraph) wrote out a regions folder under a directory folder. The purpose of this notebook is to copy these files to the new proc imagery bucket, with a new folder strucutre, to be imported into VIAME-Web-AMLR.\n",
    "\n",
    "Rsync files in GCS from bucket to bucket. Specifically, rsync the regions directories to the new amlr-gliders-imagery-proc-dev bucket\n",
    "\n",
    "NOTE: the output directories are copied using a different strategy, over in 'file_copy_...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8ce78-589d-4097-bce1-33ff41543659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from filemgmt.utils import rsync_imagery_proc_regions, create_pre\n",
    "from filemgmt.gcs import list_blobs_with_prefix\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42599df0-917d-4849-87f0-8a6edfdbcea5",
   "metadata": {},
   "source": [
    "## Set variable names\n",
    "User tasks: update variable names as necessary in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01166d-b007-4002-9f2e-c0c8b463643d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_source_name      = \"amlr-imagery-proc-dev\"\n",
    "bucket_destination_name = \"amlr-gliders-imagery-proc-dev\"\n",
    "\n",
    "glider_deployment = \"amlr08-20220513\"\n",
    "pre_source, pre_destination = create_pre(glider_deployment)\n",
    "\n",
    "file_prefix    = f\"{pre_source}/{glider_deployment}/shadowgraph/images/Dir000\"\n",
    "file_substr    = \"/regions/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb88eb-b89c-4bc8-b5fb-5b54c4e8f057",
   "metadata": {},
   "source": [
    "## Generate source list\n",
    "\n",
    "Generate the list of files to rename. \n",
    "\n",
    "NOTE: It likely would be more efficient and just as 'robust' to just generate the source strings using a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a8216-5552-491a-ac3e-6bc060f25714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_list_orig = list_blobs_with_prefix(\n",
    "    bucket_source_name, file_prefix, file_substr=file_substr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995d27d-1df9-4606-a269-0847872ea7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"there are {len(file_list_orig)} files with substring '{file_substr}' \" +\n",
    "      f\"with the prefix '{bucket_source_name}/{file_prefix}'\")\n",
    "for i in file_list_orig[0:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619a552-f9b4-41a0-b0c0-39c501ee0ad0",
   "metadata": {},
   "source": [
    "Create a new file list by filtering for the Directory paths only. Then create a list of the rsync source strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39eb11-d23e-47a3-bc0f-698cd8767589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rsync_list_source = [f\"gs://{bucket_source_name}/{i[:-1]}\" for i in file_list_orig if len(i) <= 70]\n",
    "print(f\"There are {len(rsync_list_source)} directory paths\")\n",
    "print(\"The rsync source strings are as follows:\")\n",
    "for i in rsync_list_source:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731e298-12d9-499a-b61e-15cae884b0c3",
   "metadata": {},
   "source": [
    "## Run rsync commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66373bfe-87b1-4af1-b4ec-4104f1d9bbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for src in rsync_list_source:\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(src)\n",
    "    rsync_out = rsync_imagery_proc_regions(\n",
    "        src, \n",
    "        f\"{bucket_source_name}/{pre_source}\",\n",
    "        f\"{bucket_destination_name}/{pre_destination}\", \n",
    "        text_only=True\n",
    "    )\n",
    "    print(rsync_out)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-muggle-gcp-files-muggle-gcp-files",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "muggle-gcp-files (Local)",
   "language": "python",
   "name": "conda-env-muggle-gcp-files-muggle-gcp-files"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
